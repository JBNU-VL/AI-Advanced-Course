{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import imp\n",
    "try:\n",
    "    imp.find_module('jupyterplot')\n",
    "    from jupyterplot import ProgressPlot\n",
    "except ImportError:\n",
    "    !pip install jupyterplot\n",
    "    from jupyterplot import ProgressPlot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets as D\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from utils import train_step, test_step\n",
    "from utils import simulate_scheduler\n",
    "from utils import BaselineModel\n",
    "from utils import get_cifar10_dataset, make_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate를 실시간으로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "phases = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset = get_cifar10_dataset()\n",
    "loader = make_dataloader(cifar10_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaselineModel()\n",
    "nets = [\n",
    "    BaselineModel().to(device)\n",
    "    for _ in range(2)\n",
    "]\n",
    "_ = [net.load_state_dict(deepcopy(base_cnn.state_dict())) for net in nets]\n",
    "\n",
    "optimizers = [\n",
    "    torch.optim.SGD(net.parameters(), learning_rate, 0.9)\n",
    "    for net in nets\n",
    "]\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "lrs = simulate_scheduler(gamma, num_epochs)\n",
    "plt.plot(lrs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    torch.optim.SGD(net.parameters(), learning_rate, 0.85)\n",
    "    for net in nets\n",
    "]\n",
    "sched = torch.optim.lr_scheduler.ExponentialLR(optimizers[1], gamma)\n",
    "conditions = ['without_scheduler', 'with_scheduler']\n",
    "pp = ProgressPlot(\n",
    "    plot_names=phases,\n",
    "    line_names=conditions,\n",
    "    x_lim=[0, num_epochs*len(loader['train'])],\n",
    "    x_label='Iteration',\n",
    "    y_lim=[[0, 3], [50, 100]]\n",
    ")\n",
    "\n",
    "accs = [0, 0]\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, target in loader['train']:\n",
    "        losses = [\n",
    "            train_step(net, inputs, target, optimizer, criterion, device)\n",
    "            for net, optimizer in zip(nets, optimizers)\n",
    "        ]\n",
    "        pp.update([losses, accs])\n",
    "    \n",
    "    corrects = [0, 0]\n",
    "    for inputs, target in loader['test']:\n",
    "        outputs = [\n",
    "            test_step(net, inputs, target, device=device)[0]\n",
    "            for net in nets\n",
    "        ]\n",
    "        corrects = [\n",
    "            (correct + (output.argmax(1).cpu() == target).sum()).item()\n",
    "            for correct, output in zip(corrects, outputs)\n",
    "        ]\n",
    "        \n",
    "    accs = [\n",
    "        correct / len(cifar10_dataset['test']) * 100\n",
    "        for correct in corrects\n",
    "    ]\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} accuracy ', end='')\n",
    "    lrs = [learning_rate, sched.get_lr()[0]]\n",
    "    for cond, acc, lr in zip(conditions, accs, lrs):\n",
    "        print(f'{cond}: lr {lr:.5f}-{acc:.2f}', end=' ')\n",
    "    print()\n",
    "    sched.step()\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd-attention",
   "language": "python",
   "name": "kd-attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
