{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets as D\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from utils import train_step, test_step\n",
    "from utils import simulate_scheduler\n",
    "from utils import BaselineModel\n",
    "from utils import get_cifar10_dataset, make_dataloader\n",
    "from utils import fetch_data, sample_random_data, show_images\n",
    "\n",
    "from utils import check_install_module\n",
    "check_install_module(\"plotly\")\n",
    "check_install_module(\"jupyterplot\")\n",
    "\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from jupyterplot import ProgressPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "phases = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = get_cifar10_dataset()\n",
    "random_augment_dataset = get_cifar10_dataset(random_crop=True)\n",
    "loader = make_dataloader(normal_dataset, batch_size)\n",
    "rloader = make_dataloader(random_augment_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일반 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, target = fetch_data(normal_dataset['train'], [10, 100, 1000, 10000, 52])\n",
    "titles = [normal_dataset['train'].classes[idx] for idx in target]\n",
    "show_images(images.permute(0,2,3,1), titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 무작위 확대 / 이동 한 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, target = fetch_data(random_augment_dataset['train'], [10, 100, 1000, 10000, 52])\n",
    "titles = [normal_dataset['train'].classes[idx] for idx in target]\n",
    "show_images(images.permute(0,2,3,1), titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaselineModel()\n",
    "nets = [\n",
    "    BaselineModel().to(device)\n",
    "    for _ in range(2)\n",
    "]\n",
    "_ = [net.load_state_dict(deepcopy(base_cnn.state_dict())) for net in nets]\n",
    "\n",
    "optimizers = [\n",
    "    torch.optim.SGD(net.parameters(), learning_rate, 0.9)\n",
    "    for net in nets\n",
    "]\n",
    "scheds = [\n",
    "    torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
    "    for optimizer in optimizers\n",
    "]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "conditions = ['without_augmentation', 'with_augmentation']\n",
    "pp = ProgressPlot(\n",
    "    plot_names=phases,\n",
    "    line_names=conditions,\n",
    "    x_lim=[0, num_epochs*len(loader['train'])],\n",
    "    x_label='Iteration',\n",
    "    y_lim=[[0, 3], [50, 100]]\n",
    ")\n",
    "logs = [dict(loss=[], accuracy=[]) for _ in conditions]\n",
    "\n",
    "accs = [0, 0]\n",
    "for epoch in range(num_epochs):\n",
    "    for nbatch, rbatch in zip(loader['train'], rloader['train']):\n",
    "        losses = [\n",
    "            train_step(net, *batch, optimizer, criterion, device)\n",
    "            for net, optimizer, batch in zip(nets, optimizers, [nbatch, rbatch])\n",
    "        ]\n",
    "        pp.update([losses, accs])\n",
    "        [log['loss'].append(loss) for log, loss in zip(logs, losses)]\n",
    "    \n",
    "    corrects = [0, 0]\n",
    "    for inputs, target in loader['test']:\n",
    "        outputs = [\n",
    "            test_step(net, inputs, target, device=device)[0]\n",
    "            for net in nets\n",
    "        ]\n",
    "        corrects = [\n",
    "            (correct + (output.argmax(1).cpu() == target).sum()).item()\n",
    "            for correct, output in zip(corrects, outputs)\n",
    "        ]\n",
    "        \n",
    "    accs = [\n",
    "        correct / len(normal_dataset['test']) * 100\n",
    "        for correct in corrects\n",
    "    ]\n",
    "    [log['accuracy'].append(acc) for log, acc in zip(logs, accs)]\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} accuracy ', end='')\n",
    "    for cond, acc in zip(conditions, accs):\n",
    "        print(f'{cond}: {acc:.2f}', end=' ')\n",
    "    print()\n",
    "    [sched.step() for sched in scheds]\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = {lr: log['loss'] for lr, log in zip(conditions, logs)}\n",
    "acc_df = {lr: log['accuracy'] for lr, log in zip(conditions, logs)}\n",
    "\n",
    "iteration = list(range(len(loss_df[conditions[0]])))\n",
    "ext_epoch = [iep+len(loader['train']) for iep in range(0, len(iteration), len(loader['train']))]\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_traces(\n",
    "    [go.Scatter(x=iteration, y=loss_df[lr], name=lr) for lr in conditions],\n",
    "    secondary_ys=[False for _ in conditions]\n",
    ")\n",
    "\n",
    "fig.add_traces(\n",
    "    [go.Scatter(x=ext_epoch, y=acc_df[lr], name=lr) for lr in conditions],\n",
    "    secondary_ys=[True for _ in conditions]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Iteration')\n",
    "fig.update_yaxes(title_text='Loss', secondary_y=False, range=[0, 3])\n",
    "fig.update_yaxes(title_text='Accuracy', secondary_y=True, range=[0,100])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
