{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils import train_step, test_step\n",
    "from utils import BaselineModel\n",
    "from utils import get_cifar10_dataset, make_dataloader\n",
    "from utils import check_install_module\n",
    "check_install_module(\"plotly\")\n",
    "check_install_module(\"jupyterplot\")\n",
    "\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from jupyterplot import ProgressPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate\n",
    "![](https://mblogthumb-phinf.pstatic.net/MjAxOTA0MTlfMTg2/MDAxNTU1NjM0NTM2NjQw.ReuAZtSQXIgyGA98iiI_222dHBOMcjMRrew68NU3USUg.NLr7L3nuWQvE4WHGIUoELeQo2nnhghrObFAJVVB-MDQg.PNG.ollehw/image.png?type=w800)\n",
    "\n",
    "- 여러가지 학습률을 모델이 적용해 훈련이 어떻게 되는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rates = [1., 0.1, 0.01, 0.001]\n",
    "momentum = 0.9\n",
    "phases = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset = get_cifar10_dataset()\n",
    "loader = make_dataloader(cifar10_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaselineModel().to(device)\n",
    "\n",
    "nets = [BaselineModel().to(device) for _ in learning_rates]\n",
    "_ = [net.load_state_dict(deepcopy(base_cnn.state_dict())) for net in nets]\n",
    "\n",
    "optimizers = [\n",
    "    torch.optim.SGD(net.parameters(), lr, 0.9)\n",
    "    for net, lr in zip(nets, learning_rates)\n",
    "]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "pp = ProgressPlot(\n",
    "    plot_names=phases,\n",
    "    line_names=list(map(str, learning_rates)),\n",
    "    x_lim=[0, num_epochs*len(loader['train'])],\n",
    "    x_label='Iteration',\n",
    "    y_lim=[[0, 3], [0, 100]]\n",
    ")\n",
    "logs = [dict(loss=[], accuracy=[]) for _ in learning_rates]\n",
    "\n",
    "accs = [0] * len(learning_rates)\n",
    "for epoch in range(num_epochs):\n",
    "    for iteration, (inputs, target) in enumerate(loader['train']):\n",
    "        losses = [\n",
    "            train_step(net, inputs, target, optimizer, criterion, device)\n",
    "            for net, optimizer in zip(nets, optimizers)\n",
    "        ]\n",
    "        pp.update([losses, accs])\n",
    "        [log['loss'].append(loss) for log, loss in zip(logs, losses)]\n",
    "    \n",
    "    corrects = [0] * len(learning_rates)\n",
    "    for inputs, target in loader['test']:\n",
    "        outputs = [\n",
    "            test_step(net, inputs, target, device=device)[0]\n",
    "            for net in nets\n",
    "        ]\n",
    "        corrects = [\n",
    "            (correct + (output.argmax(1).cpu() == target).sum()).item()\n",
    "            for correct, output in zip(corrects, outputs)\n",
    "        ]\n",
    "        \n",
    "    accs = [\n",
    "        correct / len(cifar10_dataset['test']) * 100\n",
    "        for correct in corrects\n",
    "    ]\n",
    "    [log['accuracy'].append(acc) for log, acc in zip(logs, accs)]\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} accuracy ', end='')\n",
    "    for lr, acc in zip(learning_rates, accs):\n",
    "        print(f'{lr}: {acc:.2f}', end=' ')\n",
    "    print()\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = {lr: log['loss'] for lr, log in zip(learning_rates, logs)}\n",
    "acc_df = {lr: log['accuracy'] for lr, log in zip(learning_rates, logs)}\n",
    "\n",
    "iteration = list(range(len(loss_df[learning_rates[0]])))\n",
    "ext_epoch = [iep+len(loader['train']) for iep in range(0, len(iteration), len(loader['train']))]\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_traces(\n",
    "    [go.Scatter(x=iteration, y=loss_df[lr], name=lr) for lr in learning_rates],\n",
    "    secondary_ys=[False for _ in learning_rates]\n",
    ")\n",
    "\n",
    "fig.add_traces(\n",
    "    [go.Scatter(x=ext_epoch, y=acc_df[lr], name=lr) for lr in learning_rates],\n",
    "    secondary_ys=[True for _ in learning_rates]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Iteration')\n",
    "fig.update_yaxes(title_text='Loss', secondary_y=False, range=[0, 3])\n",
    "fig.update_yaxes(title_text='Accuracy', secondary_y=True, range=[0,100])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
