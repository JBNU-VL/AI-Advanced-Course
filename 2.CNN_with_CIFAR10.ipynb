{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import imp\n",
    "try:\n",
    "    imp.find_module('jupyterplot')\n",
    "    from jupyterplot import ProgressPlot\n",
    "except ImportError:\n",
    "    !pip install jupyterplot\n",
    "    from jupyterplot import ProgressPlot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets as D\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from utils import sample_random_data\n",
    "from utils import show_images\n",
    "from utils import train_step, test_step\n",
    "from utils import BaselineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10에서 모델 훈련해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNeuralNetworks(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16,\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cnn = ConvolutionNeuralNetworks()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['train', 'test']\n",
    "transform = T.Compose([T.Resize((32, 32)), T.ToTensor()])\n",
    "cifar10_dataset = {\n",
    "    phase: D.CIFAR10(\n",
    "        'data', train=phase=='train', transform=transform, download=True\n",
    "    )\n",
    "    for phase in phases\n",
    "}\n",
    "loader = {\n",
    "    phase: DataLoader(\n",
    "        cifar10_dataset[phase],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=phase=='train'\n",
    "    )\n",
    "    for phase in ['train', 'test']\n",
    "}\n",
    "images, target = sample_random_data(cifar10_dataset['train'])\n",
    "titles = [cifar10_dataset['train'].classes[idx] for idx in target]\n",
    "show_images(images.permute(0,2,3,1), titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvolutionNeuralNetworks().to(device)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), learning_rate, 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "pp = ProgressPlot(\n",
    "    plot_names=phases,\n",
    "    line_names=['loss', 'accuracy'],\n",
    "    x_lim=[0, num_epochs*len(loader['train'])],\n",
    "    x_label='Iteration',\n",
    "    y_lim=[[0, 2], [0, 100]]\n",
    ")\n",
    "\n",
    "accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, target in loader['train']:\n",
    "        loss = train_step(cnn, inputs, target, optimizer, criterion, device)\n",
    "        pp.update([[loss, -1], [-500, accuracy]])\n",
    "    \n",
    "    corrects = 0\n",
    "    for inputs, target in loader['test']:\n",
    "        output, _ = test_step(cnn, inputs, target, device=device)\n",
    "        corrects += (output.argmax(1).cpu() == target).sum().item()\n",
    "    accuracy = corrects / len(cifar10_dataset['test']) * 100\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} accuracy {accuracy:.2f}')\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = sample_random_data(cifar10_dataset['test'], num=25)\n",
    "scores = cnn(images.to(device))\n",
    "predicted = scores.argmax(1).detach().cpu()\n",
    "correctness = (predicted == torch.as_tensor(targets))\n",
    "\n",
    "target_names = [cifar10_dataset['test'].classes[t] for t in targets]\n",
    "pred_names = [cifar10_dataset['test'].classes[t] for t in predicted]\n",
    "titles = [f'target {t}\\npredicted as {p}\\n{\"correct\" if c else \"WRONG\"}'\n",
    "          for t, p, c in zip(target_names, pred_names, correctness)]\n",
    "show_images(images.permute(0,2,3,1), titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
