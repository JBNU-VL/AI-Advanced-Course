{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    imp.find_module('jupyterplot')\n",
    "    from jupyterplot import ProgressPlot\n",
    "except ImportError:\n",
    "    !pip install jupyterplot\n",
    "    from jupyterplot import ProgressPlot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets as D\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from utils import invest_size\n",
    "from utils import sample_random_data\n",
    "from utils import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Classification\n",
    "\n",
    "![](https://www.researchgate.net/publication/332284670/figure/fig1/AS:745591005007874@1554774156651/Example-of-a-CNN-for-image-classification.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image ? Feature map?\n",
    "## Image\n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--7uHGwEG8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/HgnybWG/rgb.png)\n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--BXoVOWNw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/yyDtW47/own2d.png)\n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--L7_r7KuE--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/hWdkRpd/last.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature map\n",
    "\n",
    "Neural network의 각 레이어가 다음 레이어로 전달하는 정보\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*LlRAQHT0ktl_33VUnDhoIg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution layer\n",
    "\n",
    "![](https://a.disquscdn.com/get?url=http%3A%2F%2Fi.imgur.com%2FOc1zZOM.png&key=LkQy1acZbmFHr9m1gWJUvA&w=800&h=387)\n",
    "\n",
    "- 컨볼루션 레이어의 stride, padding을 변화시키며 출력 feature의 크기를 확인해보기\n",
    "\n",
    "#### $N_{out}=\\lfloor \\frac{N_{in}+2\\cdot padding-kernel size}{stride} \\rfloor+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ex) $stride=1$, $kernelsize=3$, $padding=1$, 컨볼루션 레이어에\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$5\\times 5$ 크기의 입력이 들어가면\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$5\\times 5$ 크기의 출력이 나옴\n",
    "![](https://theano-pymc.readthedocs.io/en/latest/_images/same_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ex) $stride=2$, $kernelsize=3$, $padding=1$, 컨볼루션 레이어에\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$6\\times 6$ 크기의 입력이 들어가면\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$3\\times 3$ 크기의 출력이 나옴\n",
    "![](https://theano-pymc.readthedocs.io/en/latest/_images/padding_strides_odd.gif)\n",
    "\n",
    "https://theano-pymc.readthedocs.io/en/latest/tutorial/conv_arithmetic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_channels = 1\n",
    "size_W = 24\n",
    "size_H = 24\n",
    "\n",
    "padding = 1\n",
    "stride = 2\n",
    "kernel_size = 3\n",
    "out_channels = 1\n",
    "\n",
    "inputs = torch.randn(batch_size, num_channels, size_W, size_H)\n",
    "\n",
    "convolution_layer = nn.Conv2d(\n",
    "    in_channels=num_channels,\n",
    "    out_channels=out_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    padding=padding\n",
    ")\n",
    "invest_size(inputs, convolution_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling Layer\n",
    "![](https://media.vlpt.us/images/tmddn0311/post/2abc7701-340d-494f-880c-01238a3439b4/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "stride = 2\n",
    "padding = 0\n",
    "\n",
    "inputs = torch.tensor([[\n",
    "    [12, 20, 30, 0],\n",
    "    [8, 12, 2, 0],\n",
    "    [34, 70, 37, 4],\n",
    "    [112, 100, 25, 12]\n",
    "]], dtype=torch.float)\n",
    "\n",
    "maxpooling_layer = nn.MaxPool2d(\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    padding=padding\n",
    ")\n",
    "\n",
    "invest_size(inputs, maxpooling_layer)\n",
    "print(maxpooling_layer(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNeuralNetworks(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=16,\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "cnn = ConvolutionNeuralNetworks()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = T.Compose([T.Resize((32, 32)), T.ToTensor()])\n",
    "mnist_dataset = {\n",
    "    'train': D.MNIST(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        transform=data_transform,\n",
    "        download=True\n",
    "    ),\n",
    "    'test': D.MNIST(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        transform=data_transform\n",
    "    )\n",
    "}\n",
    "print(f'훈련 집합의 데이터 개수: {len(mnist_dataset[\"train\"])}')\n",
    "print(f'테스트 집합의 데이터 개수: {len(mnist_dataset[\"test\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = sample_random_data(mnist_dataset['train'])\n",
    "show_images(images, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvolutionNeuralNetworks().to(device)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate, momentum=momentum)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "data_loader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset=mnist_dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        dataset=mnist_dataset['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f'한 epoch 당 iteration 수: {len(mnist_dataset[\"train\"])} / {batch_size} = {len(data_loader[\"train\"])}')\n",
    "\n",
    "loss_basket = []\n",
    "accuracy_basket = []\n",
    "\n",
    "pp = ProgressPlot(\n",
    "    plot_names=['train', 'test'],\n",
    "    line_names=['loss', 'accuracy'],\n",
    "    x_lim=[0, num_epochs*len(data_loader['train'])],\n",
    "    x_label='Iteration',\n",
    "    y_lim=[[0, 2.5], [95, 100]]\n",
    ")\n",
    "accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    cnn.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    for iteration, (inputs, target) in enumerate(data_loader['train']):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        output = cnn(inputs)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_basket.append(loss.item())\n",
    "        pp.update([[loss.item(), -1], [0, accuracy]])\n",
    "    \n",
    "    cnn.eval()\n",
    "    corrects = 0\n",
    "    torch.set_grad_enabled(False)\n",
    "    for inputs, target in data_loader['test']:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        output = cnn(inputs)\n",
    "        scores, predicted_classes = output.max(dim=1)\n",
    "        \n",
    "        corrects += (predicted_classes == target).sum().item()\n",
    "        \n",
    "    accuracy = corrects/len(mnist_dataset[\"test\"])*100\n",
    "    accuracy_basket.append(accuracy)\n",
    "    print(f'Epoch: {epoch+1} accuracy {accuracy:.2f}')\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_basket)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accuracy_basket)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 시킨 모델 테스트\n",
    "- 반복적으로 실행하여 틀린 샘플 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = sample_random_data(mnist_dataset['test'], num=25)\n",
    "\n",
    "scores = cnn(images.to(device))\n",
    "predicted = scores.argmax(1).detach().cpu()\n",
    "correctness = (predicted == torch.as_tensor(targets))\n",
    "titles = [f'target {t}\\npredicted as {p}\\n{\"correct\" if c else \"WRONG\"}'\n",
    "          for t, p, c in zip(targets, predicted, correctness)]\n",
    "show_images(images, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd-attention",
   "language": "python",
   "name": "kd-attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
